From 17f2a373b4df545be779c9ec55df8193712b2aef Mon Sep 17 00:00:00 2001
From: Michal Kubecek <mkubecek@suse.cz>
Date: Mon, 10 Sep 2018 10:12:24 +0200
Subject: [PATCH 42/44] ethtool: implement GET_RXFLOW message

Request the information provided by ETHTOOL_GRSSH, ETHTOOL_GRXRINGS,
ETHTOOL_GRXFH and ETHTOOL_GRXFHINDIR ioctl commands. This allows to query

  - ring count
  - hash function
  - hash key
  - hash fields for flow types
  - indirection table

for a device and potentially also RSS context.

Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
---
 Documentation/networking/ethtool-netlink.txt | 125 ++++-
 include/uapi/linux/ethtool_netlink.h         | 101 ++++
 net/ethtool/Makefile                         |   2 +-
 net/ethtool/netlink.c                        |   8 +
 net/ethtool/netlink.h                        |   1 +
 net/ethtool/rxflow.c                         | 463 +++++++++++++++++++
 6 files changed, 695 insertions(+), 5 deletions(-)
 create mode 100644 net/ethtool/rxflow.c

diff --git a/Documentation/networking/ethtool-netlink.txt b/Documentation/networking/ethtool-netlink.txt
index 3da6e4ddb9e4..590186764643 100644
--- a/Documentation/networking/ethtool-netlink.txt
+++ b/Documentation/networking/ethtool-netlink.txt
@@ -132,6 +132,8 @@ List of message types
     ETHNL_CMD_GET_PARAMS
     ETHNL_CMD_SET_PARAMS
     ETHNL_CMD_ACT_NWAY_RST
+    ETHNL_CMD_GET_RXFLOW
+    ETHNL_CMD_SET_RXFLOW		response only
 
 All constants use ETHNL_CMD_ prefix, usually followed by "GET", "SET" or "ACT"
 to indicate the type.
@@ -612,6 +614,121 @@ indicating which components _were_ actually reset (this is different from
 ioctl interface). The same message is also broadcasted as a notification.
 
 
+GET_RXFLOW
+----------
+
+Request for receive flow hashing options provided by legacy commands
+ETHTOOL_GRSSH and ETHTOOL_GRXFHINDIR. Request contents:
+
+    ETHTOOL_A_RXFLOW_DEV		(nested)	device identification
+    ETHTOOL_A_RXFLOW_INFOMASK		(u32)		info mask
+    ETHTOOL_A_RXFLOW_COMPACT		(flag)		request compact bitsets
+    ETHTOOL_A_RXFLOW_CTXOP		(u32)		context operation
+    ETHTOOL_A_RXFLOW_CONTEXT		(u32)		context id
+
+Info mask bits:
+
+    ETH_RXFLOW_IM_HASHFN		hash function
+    ETH_RXFLOW_IM_HKEY			hash key
+    ETH_RXFLOW_IM_INDTBL		indirection table
+
+If ETHTOOL_A_RXFLOW_CONTEXT is omitted or zero, data for main context are returned.
+Context id of ETH_RXFLOW_CTXOP_NEW (0xffffffff) is not allowed for
+compatibility reasons. Note that most NICs do not support multiple contexts.
+
+Reply contents:
+
+    ETHTOOL_A_RXFLOW_DEV		(nested)	device identification
+    ETHTOOL_A_RXFLOW_CONTEXT		(u32)		context id (only if not main)
+    ETHTOOL_A_RXFLOW_NRINGS		(u32)		number of Rx rings
+    ETHTOOL_A_RXFLOW_HASH_FN		(bitset)	hash function(s)
+    ETHTOOL_A_RXFLOW_HASH_KEY		(binary)	hash key
+    ETHTOOL_A_RXFLOW_HASH_OPTS		(nested)	flow hash options
+        ETHTOOL_A_RXHASHOPTS_OPT	    (nested)	    hash fields for a flow type
+	    ETHTOOL_A_RXHASHOPT_FLOWTYPE	(u32)		flow type
+	    ETHTOOL_A_RXHASHOPT_FIELDS		(bitfield32)	fields used for hash
+	    ETHTOOL_A_RXHASHOPT_DISCARD		(flag)		discard all packets
+    ETHTOOL_A_RXFLOW_INDTBL_SIZE	(u32)		indirection table size
+    ETHTOOL_A_RXFLOW_INDIR_TBL		(nested)	indirection table
+
+ETHTOOL_A_RXFLOW_NRINGS is always present in the reply (regardless of request
+info mask). For ETHTOOL_A_RXFLOW_HASH_FN, mask contains all values supported
+by kernel, value has the bit for active hash function set.
+
+ETHTOOL_A_RXFLOW_HASH_OPTS contains a series of ETHTOOL_A_RXHASHOPTS_OPT
+attributes.  Each describes header fields used to calculate the hash for flow
+type determined by ETHTOOL_A_RXHASHOPT_FLOWTYPE (*_V{4,6}_FLOW constants).
+Flag ETHTOOL_A_RXHASHOPT_DISCARD means that all packets of this type are
+dropped, othewise ETHTOOL_A_RXHASHOPT_FIELDS lists fields used for hash
+(selector has bits for all recognized fields set).
+
+ETHTOOL_A_RXFLOW_INDIR_TBL is a nested attribute consisting of a series of
+"patches" of these types:
+
+    ETHTOOL_A_INDTBL_BLOCK32		block of 32-bit values
+    ETHTOOL_A_INDTBL_BLOCK16		block of 16-bit values
+    ETHTOOL_A_INDTBL_BLOCK8		block of 8-bit values
+    ETHTOOL_A_INDTBL_PATTERN		block cycling over an interval
+    ETHTOOL_A_INDTBL_WEIGHTS		divide table according to weights
+
+Currently kernel only uses one patch for the whole table which is
+ETHTOOL_A_INDTBL_BLOCK32, ETHTOOL_A_INDTBL_BLOCK16 or ETHTOOL_A_INDTBL_BLOCK8,
+depending on the number of rings (smallest usable size is used). Userspace
+applications should not rely on this, though, as the behaviour may change in
+the future.
+
+Code interpreting indirection table starts with table filled with zeros and
+then applies patches in the order in which they appear in the message.
+
+ETHTOOL_A_INDTBL_BLOCK32 is a patch which overwrites a contiguous block in the
+table. Allowed attributes are
+
+    ETHTOOL_A_ITBLK_START		(u32)		starting offset of the block
+    ETHTOOL_A_ITBLK_LEN			(u32)		block length
+    ETHTOOL_A_ITBLK_DATA		(binary)	values to fill into the block
+
+If ETHTOOL_A_ITBLK_START is omitted, 0 is used. If ETHTOOL_A_ITBLK_LEN is
+omitted, the block is assumed to span to the end of the table.
+ETHTOOL_A_ITBLK_DATA consists of an array of unsigned 32-bit values which are
+copied into the table starting at the offset determined by
+ETHTOOL_A_ITBLK_START (or zero). If the array is longer than block length, it
+is truncated. If the array is shorted, its copies are repeated to fill the
+whole block.
+
+ETHTOOL_A_INDTBL_BLOCK16 and ETHTOOL_A_INDTBL_BLOCK8 are interpreted in the
+same way except ETHTOOL_A_ITBLK_DATA consists of an array of u16 and u8
+values, respectively.
+
+ETHTOOL_A_INDTBL_PATTERN is a patch which overwrites a contiguous block by
+numbers cycling over an interval. Allowed attributes are
+
+    ETHTOOL_A_ITPAT_START		(u32)		starting offset of the block
+    ETHTOOL_A_ITPAT_LEN			(u32)		block length
+    ETHTOOL_A_ITPAT_MIN_RING		(u32)		minimum ring number to use
+    ETHTOOL_A_ITPAT_MAX_RING		(u32)		maximum ring number to use
+    ETHTOOL_A_ITPAT_OFFSET		(u32)		offset to shift values by
+
+ETHTOOL_A_ITPAT_START and ETHTOOL_A_ITPAT_END have the same meaning and
+defaults as ETHTOOL_A_ITBLK_* above. The block is filled by repeating values
+from ETHTOOL_A_ITPAT_MIN_RING (defaults to 0) to ETHTOOL_A_ITPAT_MAX_RING
+(defaults to maximum ring number). By default, the starting value is
+ETHTOOL_A_ITPAT_MIN_RING; if ETHTOOL_A_ITPAT_OFFSET is used, its value is
+added (modulo interval length).
+
+ETHTOOL_A_INDTBL_WEIGHTS divides the whole table according to specified
+weights (the exact result is supposed to be the same as traditional code for
+"weight" option of "ethtool -X" produces). Allowed values are
+
+    ETHTOOL_A_ITWGHT_VALUES		(binary)	values to use
+    ETHTOOL_A_ITWGHT_WEIGHTS		(binary)	weights to divide by
+
+ETHTOOL_A_ITWGHT_WEIGHTS is an array of u32 weights. The sum of all weights
+must be strictly positive and must not exceed table size. If
+ETHTOOL_A_ITWGHT_VALUES is present, it must be an u32 array of equal size with
+values (ring numbers) these weights correspond to. If ETHTOOL_A_ITWGHT_VALUES
+is omitted, values from 0 to number of weights minus one are used.
+
+
 Request translation
 -------------------
 
@@ -660,11 +777,11 @@ ETHTOOL_GFLAGS			ETHNL_CMD_GET_SETTINGS
 ETHTOOL_SFLAGS			ETHNL_CMD_SET_SETTINGS
 ETHTOOL_GPFLAGS			ETHNL_CMD_GET_SETTINGS
 ETHTOOL_SPFLAGS			ETHNL_CMD_SET_SETTINGS
-ETHTOOL_GRXFH			n/a
+ETHTOOL_GRXFH			ETHNL_CMD_GET_RXFLOW
 ETHTOOL_SRXFH			n/a
 ETHTOOL_GGRO			ETHNL_CMD_GET_SETTINGS
 ETHTOOL_SGRO			ETHNL_CMD_SET_SETTINGS
-ETHTOOL_GRXRINGS		n/a
+ETHTOOL_GRXRINGS		ETHNL_CMD_GET_RXFLOW
 ETHTOOL_GRXCLSRLCNT		n/a
 ETHTOOL_GRXCLSRULE		n/a
 ETHTOOL_GRXCLSRLALL		n/a
@@ -675,7 +792,7 @@ ETHTOOL_RESET			ETHNL_CMD_ACT_RESET
 ETHTOOL_SRXNTUPLE		n/a
 ETHTOOL_GRXNTUPLE		n/a
 ETHTOOL_GSSET_INFO		ETHNL_CMD_GET_STRSET
-ETHTOOL_GRXFHINDIR		n/a
+ETHTOOL_GRXFHINDIR		ETHNL_CMD_GET_RXFLOW
 ETHTOOL_SRXFHINDIR		n/a
 ETHTOOL_GFEATURES		ETHNL_CMD_GET_SETTINGS
 ETHTOOL_SFEATURES		ETHNL_CMD_SET_SETTINGS
@@ -689,7 +806,7 @@ ETHTOOL_GMODULEINFO		n/a
 ETHTOOL_GMODULEEEPROM		n/a
 ETHTOOL_GEEE			ETHNL_CMD_GET_PARAMS
 ETHTOOL_SEEE			ETHNL_CMD_SET_PARAMS
-ETHTOOL_GRSSH			n/a
+ETHTOOL_GRSSH			ETHNL_CMD_GET_RXFLOW
 ETHTOOL_SRSSH			n/a
 ETHTOOL_GTUNABLE		n/a
 ETHTOOL_STUNABLE		n/a
diff --git a/include/uapi/linux/ethtool_netlink.h b/include/uapi/linux/ethtool_netlink.h
index 85857101c0c0..d03bb4b56b10 100644
--- a/include/uapi/linux/ethtool_netlink.h
+++ b/include/uapi/linux/ethtool_netlink.h
@@ -25,6 +25,8 @@ enum {
 	ETHNL_CMD_ACT_NWAY_RST,
 	ETHNL_CMD_ACT_PHYS_ID,
 	ETHNL_CMD_ACT_RESET,
+	ETHNL_CMD_GET_RXFLOW,
+	ETHNL_CMD_SET_RXFLOW,		/* only for reply */
 
 	__ETHNL_CMD_CNT,
 	ETHNL_CMD_MAX = (__ETHNL_CMD_CNT - 1)
@@ -446,6 +448,105 @@ enum {
 	ETHTOOL_A_RESET_MAX = (__ETHTOOL_A_RESET_CNT - 1)
 };
 
+/* GET_RXFLOW / SET_RXFLOW */
+
+enum {
+	ETHTOOL_A_RXFLOW_UNSPEC,
+	ETHTOOL_A_RXFLOW_DEV,			/* nest - ETHTOOL_A_DEV_* */
+	ETHTOOL_A_RXFLOW_INFOMASK,		/* u32 */
+	ETHTOOL_A_RXFLOW_COMPACT,		/* flag */
+	ETHTOOL_A_RXFLOW_CTXOP,			/* u32 - ETH_RXFLOW_CTXOP_* */
+	ETHTOOL_A_RXFLOW_CONTEXT,		/* u32 */
+	ETHTOOL_A_RXFLOW_NRINGS,		/* u32 */
+	ETHTOOL_A_RXFLOW_HASH_FN,		/* bitset */
+	ETHTOOL_A_RXFLOW_HASH_KEY,		/* binary */
+	ETHTOOL_A_RXFLOW_HASH_OPTS,		/* nest - ETHTOOL_A_RXHASHOPTS_* */
+	ETHTOOL_A_RXFLOW_INDTBL_SIZE,		/* u32 */
+	ETHTOOL_A_RXFLOW_INDIR_TBL,		/* nest - ETHTOOL_A_INDTBL_* */
+
+	__ETHTOOL_A_RXFLOW_CNT,
+	ETHTOOL_A_RXFLOW_MAX = (__ETHTOOL_A_RXFLOW_CNT - 1)
+};
+
+#define ETH_RXFLOW_IM_INFO			(1U << 0)
+#define ETH_RXFLOW_IM_HASHFN			(1U << 1)
+#define ETH_RXFLOW_IM_HKEY			(1U << 2)
+#define ETH_RXFLOW_IM_HASHOPTS			(1U << 3)
+#define ETH_RXFLOW_IM_INDTBL			(1U << 4)
+
+#define ETH_RXFLOW_IM_ALL (ETH_RXFLOW_IM_INFO | \
+			   ETH_RXFLOW_IM_HASHFN | \
+			   ETH_RXFLOW_IM_HKEY | \
+			   ETH_RXFLOW_IM_HASHOPTS | \
+			   ETH_RXFLOW_IM_INDTBL)
+
+enum {
+	ETH_RXFLOW_CTXOP_SET,			/* set context data */
+	ETH_RXFLOW_CTXOP_NEW,			/* create new context */
+	ETH_RXFLOW_CTXOP_DEL,			/* delete existing context */
+};
+
+enum {
+	ETHTOOL_A_RXHASHOPTS_UNSPEC,
+	ETHTOOL_A_RXHASHOPTS_OPT,		/* nest - ETH_RXHASHOPT_* */
+
+	__ETHTOOL_A_RXHASHOPTS_CNT,
+	ETHTOOL_A_RXHASHOPTS_MAX = (__ETHTOOL_A_RXHASHOPTS_CNT - 1)
+};
+
+enum {
+	ETHTOOL_A_RXHASHOPT_UNSPEC,
+	ETHTOOL_A_RXHASHOPT_FLOWTYPE,		/* u32 */
+	ETHTOOL_A_RXHASHOPT_FIELDS,		/* bitfield32 */
+	ETHTOOL_A_RXHASHOPT_DISCARD,		/* flag */
+
+	__ETHTOOL_A_RXHASHOPT_CNT,
+	ETHTOOL_A_RXHASHOPT_MAX = (__ETHTOOL_A_RXHASHOPT_CNT - 1)
+};
+
+enum {
+	ETHTOOL_A_INDTBL_UNSPEC,
+	ETHTOOL_A_INDTBL_BLOCK32,		/* nest - ETH_ITBLK_* */
+	ETHTOOL_A_INDTBL_BLOCK16,		/* nest - ETH_ITBLK_* */
+	ETHTOOL_A_INDTBL_BLOCK8, 		/* nest - ETH_ITBLK_* */
+	ETHTOOL_A_INDTBL_PATTERN,		/* nest - ETH_ITPAT_* */
+	ETHTOOL_A_INDTBL_WEIGHTS,		/* nest - ETH_ITWGHT_* */
+
+	__ETHTOOL_A_INDTBL_CNT,
+	ETHTOOL_A_INDTBL_MAX = (__ETHTOOL_A_INDTBL_CNT - 1)
+};
+
+enum {
+	ETHTOOL_A_ITBLK_UNSPEC,
+	ETHTOOL_A_ITBLK_START,			/* u32 */
+	ETHTOOL_A_ITBLK_LEN,			/* u32 */
+	ETHTOOL_A_ITBLK_DATA,			/* binary */
+
+	__ETHTOOL_A_ITBLK_CNT,
+	ETHTOOL_A_ITBLK_MAX = (__ETHTOOL_A_ITBLK_CNT - 1)
+};
+
+enum {
+	ETHTOOL_A_ITPAT_UNSPEC,
+	ETHTOOL_A_ITPAT_START,			/* u32 */
+	ETHTOOL_A_ITPAT_LEN,			/* u32 */
+	ETHTOOL_A_ITPAT_MIN_RING,		/* u32 */
+	ETHTOOL_A_ITPAT_MAX_RING,		/* u32 */
+	ETHTOOL_A_ITPAT_OFFSET,			/* u32 */
+
+	__ETHTOOL_A_ITPAT_CNT,
+	ETHTOOL_A_ITPAT_MAX = (__ETHTOOL_A_ITPAT_CNT - 1)
+};
+
+enum {
+	ETHTOOL_A_ITWGHT_UNSPEC,
+	ETHTOOL_A_ITWGHT_VALUES,		/* binary */
+	ETHTOOL_A_ITWGHT_WEIGHTS,		/* binary */
+
+	__ETHTOOL_A_ITWGHT_CNT,
+	ETHTOOL_A_ITWGHT_MAX = (__ETHTOOL_A_ITWGHT_CNT - 1)
+};
+
 /* generic netlink info */
 #define ETHTOOL_GENL_NAME "ethtool"
 #define ETHTOOL_GENL_VERSION 1
diff --git a/net/ethtool/Makefile b/net/ethtool/Makefile
index b3e88cf0f4c0..a6ace735f44f 100644
--- a/net/ethtool/Makefile
+++ b/net/ethtool/Makefile
@@ -5,4 +5,4 @@ obj-y				+= ioctl.o common.o
 obj-$(CONFIG_ETHTOOL_NETLINK)	+= ethtool_nl.o
 
 ethtool_nl-y	:= netlink.o bitset.o strset.o info.o settings.o params.o \
-		   actions.o
+		   actions.o rxflow.o
diff --git a/net/ethtool/netlink.c b/net/ethtool/netlink.c
index 4eef2d403ccb..a5f1a53a9db0 100644
--- a/net/ethtool/netlink.c
+++ b/net/ethtool/netlink.c
@@ -259,6 +259,7 @@ const struct get_request_ops *get_requests[__ETHNL_CMD_CNT] = {
 	[ETHNL_CMD_GET_INFO]		= &info_request_ops,
 	[ETHNL_CMD_GET_SETTINGS]	= &settings_request_ops,
 	[ETHNL_CMD_GET_PARAMS]		= &params_request_ops,
+	[ETHNL_CMD_GET_RXFLOW]		= &rxflow_request_ops,
 };
 
 /**
@@ -732,6 +733,13 @@ static const struct genl_ops ethtool_genl_ops[] = {
 		.flags	= GENL_ADMIN_PERM,
 		.doit	= ethnl_act_reset,
 	},
+	{
+		.cmd	= ETHNL_CMD_GET_RXFLOW,
+		.doit	= ethnl_get_doit,
+		.start	= ethnl_get_start,
+		.dumpit	= ethnl_get_dumpit,
+		.done	= ethnl_get_done,
+	},
 };
 
 static const struct genl_multicast_group ethtool_nl_mcgrps[] = {
diff --git a/net/ethtool/netlink.h b/net/ethtool/netlink.h
index 0c3f045b8473..ac29fcb25449 100644
--- a/net/ethtool/netlink.h
+++ b/net/ethtool/netlink.h
@@ -261,6 +261,7 @@ extern const struct get_request_ops strset_request_ops;
 extern const struct get_request_ops info_request_ops;
 extern const struct get_request_ops settings_request_ops;
 extern const struct get_request_ops params_request_ops;
+extern const struct get_request_ops rxflow_request_ops;
 
 int ethnl_set_settings(struct sk_buff *skb, struct genl_info *info);
 int ethnl_set_params(struct sk_buff *skb, struct genl_info *info);
diff --git a/net/ethtool/rxflow.c b/net/ethtool/rxflow.c
new file mode 100644
index 000000000000..17dac7a05664
--- /dev/null
+++ b/net/ethtool/rxflow.c
@@ -0,0 +1,463 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+
+#include "netlink.h"
+#include "common.h"
+#include "bitset.h"
+
+#define RXFLOW_ALL_HASHFNS \
+       ((1 << (ETH_RSS_HASH_FUNCS_COUNT - 1)) | \
+	((1 << (ETH_RSS_HASH_FUNCS_COUNT - 1)) - 1))
+#define FLOW_TYPE_COUNT (ETHER_FLOW + 1)
+#define HASHOPT_FLOW_TYPES \
+	(BIT(TCP_V4_FLOW) | \
+	 BIT(UDP_V4_FLOW) | \
+	 BIT(SCTP_V4_FLOW) | \
+	 BIT(AH_ESP_V4_FLOW) | \
+	 BIT(TCP_V6_FLOW) | \
+	 BIT(UDP_V6_FLOW) | \
+	 BIT(SCTP_V6_FLOW) | \
+	 BIT(AH_ESP_V6_FLOW) | \
+	 BIT(AH_V4_FLOW) | \
+	 BIT(ESP_V4_FLOW) | \
+	 BIT(AH_V6_FLOW) | \
+	 BIT(ESP_V6_FLOW) | \
+	 BIT(IPV4_FLOW) | \
+	 BIT(IPV6_FLOW))
+#define RXH_ALL 0xfe
+#define RXH_COUNT 8
+
+static const struct nla_policy get_rxflow_policy[ETHTOOL_A_RXFLOW_MAX + 1] = {
+	[ETHTOOL_A_RXFLOW_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_DEV]		= { .type = NLA_NESTED },
+	[ETHTOOL_A_RXFLOW_INFOMASK]	= { .type = NLA_U32 },
+	[ETHTOOL_A_RXFLOW_COMPACT]	= { .type = NLA_FLAG },
+	[ETHTOOL_A_RXFLOW_CTXOP]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_CONTEXT]	= { .type = NLA_U32 },
+	[ETHTOOL_A_RXFLOW_NRINGS]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_HASH_FN]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_HASH_KEY]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_HASH_OPTS]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_INDTBL_SIZE]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_INDIR_TBL]	= { .type = NLA_REJECT },
+};
+
+struct rxflow_data {
+	struct common_req_info		reqinfo_base;
+	u32				req_context;
+	u32				req_flow_type;
+
+	/* everything below here will be reset for each device in dumps */
+	struct common_reply_data	repdata_base;
+	unsigned int			entry_size;
+	u32				indtbl_size;
+	u32				hkey_size;
+	u32				n_rings;
+	u32				*indir_tbl;
+	u8				*hkey;
+	u32				hash_fn;
+	u32				hash_fields[FLOW_TYPE_COUNT];
+};
+
+static int parse_rxflow(struct common_req_info *req_info, struct sk_buff *skb,
+			struct genl_info *info, const struct nlmsghdr *nlhdr)
+{
+	struct rxflow_data *data =
+		container_of(req_info, struct rxflow_data, reqinfo_base);
+	struct nlattr *tb[ETHTOOL_A_RXFLOW_MAX + 1];
+	int ret;
+
+	ret = nlmsg_parse(nlhdr, GENL_HDRLEN, tb, ETHTOOL_A_RXFLOW_MAX,
+			  get_rxflow_policy, info->extack);
+	if (ret < 0)
+		return ret;
+
+	if (tb[ETHTOOL_A_RXFLOW_DEV]) {
+		req_info->dev = ethnl_dev_get(info, tb[ETHTOOL_A_RXFLOW_DEV]);
+		if (IS_ERR(req_info->dev)) {
+			ret = PTR_ERR(req_info->dev);
+			req_info->dev = NULL;
+			return ret;
+		}
+	}
+	if (tb[ETHTOOL_A_RXFLOW_INFOMASK])
+		req_info->req_mask = nla_get_u32(tb[ETHTOOL_A_RXFLOW_INFOMASK]);
+	if (tb[ETHTOOL_A_RXFLOW_COMPACT])
+		req_info->compact = true;
+	if (tb[ETHTOOL_A_RXFLOW_CONTEXT])
+		data->req_context = nla_get_u32(tb[ETHTOOL_A_RXFLOW_CONTEXT]);
+	if (req_info->req_mask == 0)
+		req_info->req_mask = ETH_RXFLOW_IM_ALL;
+
+	return 0;
+}
+
+static int alloc_hkey(struct rxflow_data *data)
+{
+	if (!data->hkey_size)
+		return -EOPNOTSUPP;
+	data->hkey = kzalloc(data->hkey_size, GFP_KERNEL);
+	return data->hkey ? 0 : -ENOMEM;
+}
+
+static int get_hash_opts(struct net_device *dev, struct rxflow_data *data)
+{
+	struct ethtool_rxnfc cmd = {
+		.cmd		= ETHTOOL_GRXFH,
+		.rss_context	= data->req_context,
+	};
+	u32 req_flow_type = data->req_flow_type;
+	u32 *fields = data->hash_fields;
+	unsigned int idx;
+	int ret;
+
+	for (idx = 0; idx < FLOW_TYPE_COUNT; idx++) {
+		if ((req_flow_type && idx != req_flow_type) ||
+		    !(HASHOPT_FLOW_TYPES & (1 << idx)))
+			continue;
+		cmd.flow_type = (data->req_context ? FLOW_RSS : 0) | idx;
+		ret = dev->ethtool_ops->get_rxnfc(dev, &cmd, NULL);
+		if (ret < 0)
+			continue;
+		WARN_ONCE(cmd.data >> 32,
+			  "%s: ethtool_ops->get_rxnfc() returned more than 32 flags\n",
+			  netdev_name(dev));
+		fields[idx] = (u32)cmd.data;
+	}
+
+	return 0;
+}
+
+static int alloc_indtbl(struct rxflow_data *data)
+{
+	u32 max_ring;
+
+	if (!data->indtbl_size)
+		return -EOPNOTSUPP;
+
+	max_ring = data->n_rings - 1;
+	data->entry_size = (max_ring >> 16) ? 4 : ((max_ring >> 8) ? 2 : 1);
+	data->indir_tbl = kcalloc(data->indtbl_size, sizeof(u32), GFP_KERNEL);
+	return data->indir_tbl ? 0 : -ENOMEM;
+}
+
+static int prepare_rxflow(struct common_req_info *req_info,
+			  struct genl_info *info)
+{
+	struct rxflow_data *data =
+		container_of(req_info, struct rxflow_data, reqinfo_base);
+	struct ethtool_rxnfc rx_rings = { .cmd = ETHTOOL_GRXRINGS };
+	struct net_device *dev = data->repdata_base.dev;
+	const struct ethtool_ops *ops = dev->ethtool_ops;
+	u32 req_mask = req_info->req_mask;
+	u8 hash_fn = 0;
+	int ret;
+
+	if (!ops->get_rxnfc)
+		return -EOPNOTSUPP;
+	if (data->req_context && !ops->get_rxfh_context)
+		return -EOPNOTSUPP;
+	if (!data->req_context && !ops->get_rxfh)
+		return -EOPNOTSUPP;
+
+	ret = ethnl_before_ops(dev);
+	if (ret < 0)
+		return ret;
+
+	if (req_mask & ETH_RXFLOW_IM_INDTBL)
+		req_info->req_mask = (req_mask |= ETH_RXFLOW_IM_INFO);
+	ret = dev->ethtool_ops->get_rxnfc(dev, &rx_rings, NULL);
+	if (ret < 0)
+		return ret;
+	data->n_rings = rx_rings.data;
+	if (ops->get_rxfh_indir_size)
+		data->indtbl_size = ops->get_rxfh_indir_size(dev);
+	if (ops->get_rxfh_key_size)
+		data->hkey_size = ops->get_rxfh_key_size(dev);
+
+	if (req_mask & ETH_RXFLOW_IM_HKEY) {
+		ret = alloc_hkey(data);
+		if (ret < 0)
+			req_mask &= ~ETH_RXFLOW_IM_HKEY;
+	}
+	if (req_mask & ETH_RXFLOW_IM_HASHOPTS) {
+		ret = get_hash_opts(dev, data);
+		if (ret < 0)
+			req_mask &= ~ETH_RXFLOW_IM_HASHOPTS;
+	}
+	if (req_mask & ETH_RXFLOW_IM_INDTBL) {
+		ret = alloc_indtbl(data);
+		if (ret < 0)
+			req_mask &= ~ETH_RXFLOW_IM_INDTBL;
+	}
+	if (data->req_context)
+		ret = ops->get_rxfh_context(dev, data->indir_tbl, data->hkey,
+					    &hash_fn, data->req_context);
+	else
+		ret = ops->get_rxfh(dev, data->indir_tbl, data->hkey, &hash_fn);
+	if (ret == 0)
+		data->hash_fn = hash_fn;
+	ethnl_after_ops(dev);
+
+	data->repdata_base.info_mask = req_mask;
+	if (ret == 0 && req_info->req_mask & ~req_mask)
+		warn_partial_info(info);
+	return ret;
+}
+
+static int hashopts_size(const u32 *fields)
+{
+	unsigned int i;
+	int len = 0;
+
+	for (i = 0; i < FLOW_TYPE_COUNT; i++) {
+		unsigned int i_len;
+
+		if (!fields[i])
+			continue;
+		i_len = (fields[i] & RXH_DISCARD) ?
+			0 : sizeof(struct nla_bitfield32);
+		len += nla_total_size(nla_total_size(sizeof(u32)) +
+				      nla_total_size(i_len));
+	}
+
+	return nla_total_size(len);
+}
+
+static int indtbl_size(const struct rxflow_data *data)
+{
+	unsigned int len;
+
+	/* block data */
+	len = nla_total_size(data->indtbl_size * data->entry_size);
+	/* block nest */
+	len =  nla_total_size(2 *  nla_total_size(sizeof(u32)) + len);
+	/* ETHTOOL_A_RXFLOW_INDTBL_SIZE */
+	len += nla_total_size(sizeof(u32));
+
+	return len;
+}
+
+static int rxflow_size(const struct common_req_info *req_info)
+{
+	const struct rxflow_data *data =
+		container_of(req_info, struct rxflow_data, reqinfo_base);
+	u32 info_mask = data->repdata_base.info_mask;
+	const u32 all_hashfn = RXFLOW_ALL_HASHFNS;
+	int len = 0;
+	int ret;
+
+	len += dev_ident_size();
+	if (data->req_context)
+		len += nla_total_size(sizeof(u32));
+	if (info_mask & ETH_RXFLOW_IM_INFO)
+		len += nla_total_size(sizeof(u32));
+	if (info_mask & ETH_RXFLOW_IM_HASHFN) {
+		const unsigned int flags =
+			(req_info->compact ? ETHNL_BITSET_COMPACT : 0) |
+			ETHNL_BITSET_LEGACY_NAMES;
+
+		ret = ethnl_bitset32_size(ETH_RSS_HASH_FUNCS_COUNT,
+					  &data->hash_fn, &all_hashfn,
+					  rss_hash_func_strings, flags);
+		if (ret < 0)
+			return ret;
+		len += ret;
+	}
+	if (info_mask & ETH_RXFLOW_IM_HKEY)
+		len += nla_total_size(data->hkey_size);
+	if (info_mask & ETH_RXFLOW_IM_HASHOPTS)
+		len += hashopts_size(data->hash_fields);
+	if (info_mask & ETH_RXFLOW_IM_INDTBL)
+		len += indtbl_size(data);
+
+	return len;
+}
+
+static int fill_rxflow_hashfn(struct sk_buff *skb,
+			      const struct rxflow_data *data)
+{
+	const unsigned int flags =
+		(data->reqinfo_base.compact ? ETHNL_BITSET_COMPACT : 0) |
+		ETHNL_BITSET_LEGACY_NAMES;
+	const u32 all_hashfn = RXFLOW_ALL_HASHFNS;
+	int ret;
+
+	ret = ethnl_put_bitset32(skb, ETHTOOL_A_RXFLOW_HASH_FN,
+				 ETH_RSS_HASH_FUNCS_COUNT, &data->hash_fn,
+				 &all_hashfn, rss_hash_func_strings, flags);
+	if (ret < 0)
+		return ret;
+
+	return 0;
+}
+
+static int fill_hashopts(struct sk_buff *skb, const u32 *fields)
+{
+	struct nlattr *attr_opts;
+	struct nlattr *attr_opt;
+	unsigned int i;
+	int ret;
+
+	attr_opts = nla_nest_start(skb, ETHTOOL_A_RXFLOW_HASH_OPTS);
+	if (!attr_opts)
+		return -EMSGSIZE;
+
+	for (i = 0; i < FLOW_TYPE_COUNT; i++) {
+		if (!fields[i])
+			continue;
+		ret = -EMSGSIZE;
+		attr_opt = nla_nest_start(skb, ETHTOOL_A_RXHASHOPTS_OPT);
+		if (!attr_opt)
+			goto err;
+
+		if (nla_put_u32(skb, ETHTOOL_A_RXHASHOPT_FLOWTYPE, i))
+		       goto err;
+		if (fields[i] & RXH_DISCARD) {
+			if (nla_put_flag(skb, ETHTOOL_A_RXHASHOPT_DISCARD))
+				goto err;
+		} else {
+			if (nla_put_bitfield32(skb, ETHTOOL_A_RXHASHOPT_FIELDS,
+					       fields[i], RXH_ALL))
+				goto err;
+		}
+
+		nla_nest_end(skb, attr_opt);
+	}
+
+	nla_nest_end(skb, attr_opts);
+	return 0;
+err:
+	nla_nest_cancel(skb, attr_opts);
+	return ret;
+}
+
+static int fill_indir_tbl(struct sk_buff *skb, const struct rxflow_data *data)
+{
+	struct nlattr *tbl, *block, *attr;
+	u16 block_attrtype;
+	unsigned int i;
+	int ret;
+
+	if (nla_put_u32(skb, ETHTOOL_A_RXFLOW_INDTBL_SIZE, data->indtbl_size))
+		return -EMSGSIZE;
+	tbl = nla_nest_start(skb, ETHTOOL_A_RXFLOW_INDIR_TBL);
+	if (!tbl)
+		return -EMSGSIZE;
+
+	switch(data->entry_size) {
+	case 4:
+		block_attrtype = ETHTOOL_A_INDTBL_BLOCK32;
+		break;
+	case 2:
+		block_attrtype = ETHTOOL_A_INDTBL_BLOCK16;
+		break;
+	case 1:
+		block_attrtype = ETHTOOL_A_INDTBL_BLOCK8;
+		break;
+	default:
+		WARN_ONCE(1, "invalid indir_tbl entry size %u\n",
+			  data->entry_size);
+		return -EFAULT;
+	}
+	ret = -EMSGSIZE;
+	block = nla_nest_start(skb, block_attrtype);
+	if (!block)
+		goto err;
+
+	if (nla_put_u32(skb, ETHTOOL_A_ITBLK_START, 0) ||
+	    nla_put_u32(skb, ETHTOOL_A_ITBLK_LEN, data->indtbl_size))
+		goto err;
+	switch(data->entry_size) {
+	case 4:
+		if (nla_put(skb, ETHTOOL_A_ITBLK_DATA,
+			    data->indtbl_size * sizeof(u32),
+			    data->indir_tbl))
+			goto err;
+		break;
+	case 2:
+		attr = nla_reserve(skb, ETHTOOL_A_ITBLK_DATA,
+				   data->indtbl_size * data->entry_size);
+		if (!attr)
+			goto err;
+		for (i = 0; i < data->indtbl_size; i++)
+			((u16 *)nla_data(attr))[i] = data->indir_tbl[i];
+		break;
+	case 1:
+		attr = nla_reserve(skb, ETHTOOL_A_ITBLK_DATA,
+				   data->indtbl_size * data->entry_size);
+		if (!attr)
+			goto err;
+		for (i = 0; i < data->indtbl_size; i++)
+			((u8 *)nla_data(attr))[i] = data->indir_tbl[i];
+		break;
+	}
+
+	nla_nest_end(skb, block);
+	nla_nest_end(skb, tbl);
+	return 0;
+
+err:
+	nla_nest_cancel(skb, tbl);
+	return ret;
+}
+
+static int fill_rxflow(struct sk_buff *skb,
+		       const struct common_req_info *req_info)
+{
+	const struct rxflow_data *data =
+		container_of(req_info, struct rxflow_data, reqinfo_base);
+	u32 info_mask = data->repdata_base.info_mask;
+	int ret;
+
+	if (data->req_context &&
+	    nla_put_u32(skb, ETHTOOL_A_RXFLOW_CONTEXT, data->req_context))
+		return -EMSGSIZE;
+	if ((info_mask & ETH_RXFLOW_IM_INFO) &&
+	    nla_put_u32(skb, ETHTOOL_A_RXFLOW_NRINGS, data->n_rings))
+		return -EMSGSIZE;
+	if (info_mask & ETH_RXFLOW_IM_HASHFN) {
+		ret = fill_rxflow_hashfn(skb, data);
+		if (ret < 0)
+			return ret;
+	}
+	if (info_mask & ETH_RXFLOW_IM_HKEY) {
+		if (nla_put(skb, ETHTOOL_A_RXFLOW_HASH_KEY, data->hkey_size,
+			    data->hkey))
+			return -EMSGSIZE;
+	}
+	if (info_mask & ETH_RXFLOW_IM_HASHOPTS) {
+		ret = fill_hashopts(skb, data->hash_fields);
+		if (ret < 0)
+			return ret;
+	}
+	if (info_mask & ETH_RXFLOW_IM_INDTBL) {
+		ret = fill_indir_tbl(skb, data);
+		if (ret < 0)
+			return ret;
+	}
+
+	return 0;
+}
+
+static void rxflow_cleanup(struct common_req_info *req_info)
+{
+	struct rxflow_data *data =
+		container_of(req_info, struct rxflow_data, reqinfo_base);
+
+	kfree(data->indir_tbl);
+	kfree(data->hkey);
+}
+
+const struct get_request_ops rxflow_request_ops = {
+	.request_cmd		= ETHNL_CMD_GET_RXFLOW,
+	.reply_cmd		= ETHNL_CMD_SET_RXFLOW,
+	.dev_attrtype		= ETHTOOL_A_RXFLOW_DEV,
+	.data_size		= sizeof(struct rxflow_data),
+	.repdata_offset		= offsetof(struct rxflow_data, repdata_base),
+
+	.parse_request		= parse_rxflow,
+	.prepare_data		= prepare_rxflow,
+	.reply_size		= rxflow_size,
+	.fill_reply		= fill_rxflow,
+	.cleanup		= rxflow_cleanup,
+};
-- 
2.21.0

