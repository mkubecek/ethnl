From 213f72bb9ddb4a55ea59105f5c3df316d7f326bc Mon Sep 17 00:00:00 2001
From: Michal Kubecek <mkubecek@suse.cz>
Date: Sat, 15 Sep 2018 16:02:04 +0200
Subject: [PATCH 44/44] ethtool: implement SET_RXFLOW message

Request to set data updated by ETHTOOL_SRSSH, ETHTOOL_SRXFH and
ETHTOOL_SRXFHINDIR ioctl commands. This allows to set

  - set hash function
  - set hash key
  - set hash fields for flow types
  - set indirection table
  - create a new RSS context
  - delete an RSS context

for a device.

Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
---
 Documentation/networking/ethtool-netlink.txt |  46 +-
 include/uapi/linux/ethtool_netlink.h         |   2 +-
 net/ethtool/netlink.c                        |   5 +
 net/ethtool/netlink.h                        |   1 +
 net/ethtool/rxflow.c                         | 640 +++++++++++++++++++
 5 files changed, 690 insertions(+), 4 deletions(-)

diff --git a/Documentation/networking/ethtool-netlink.txt b/Documentation/networking/ethtool-netlink.txt
index 8c3ed9525604..0d401a3a3946 100644
--- a/Documentation/networking/ethtool-netlink.txt
+++ b/Documentation/networking/ethtool-netlink.txt
@@ -133,7 +133,7 @@ List of message types
     ETHNL_CMD_SET_PARAMS
     ETHNL_CMD_ACT_NWAY_RST
     ETHNL_CMD_GET_RXFLOW
-    ETHNL_CMD_SET_RXFLOW		response only
+    ETHNL_CMD_SET_RXFLOW
 
 All constants use ETHNL_CMD_ prefix, usually followed by "GET", "SET" or "ACT"
 to indicate the type.
@@ -730,6 +730,46 @@ values (ring numbers) these weights correspond to. If ETHTOOL_A_ITWGHT_VALUES
 is omitted, values from 0 to number of weights minus one are used.
 
 
+SET_RXFLOW
+----------
+
+Request to update flow hashing options, corresponds to legacy commands
+ETHTOOL_SRSSH and ETHTOOL_SRXFHINDIR. Request contents:
+
+    ETHTOOL_A_RXFLOW_DEV		(nested)	device identification
+    ETHTOOL_A_RXFLOW_CTXOP		(u32)		context operation
+    ETHTOOL_A_RXFLOW_CONTEXT		(u32)		RSS context
+    ETHTOOL_A_RXFLOW_HASH_FN		(bitset)	hash function(s)
+    ETHTOOL_A_RXFLOW_HASH_KEY		(binary)	hash key
+    ETHTOOL_A_RXFLOW_INDIR_TBL		(nested)	indirection table description
+
+Values of ETHTOOL_A__RXFLOW_CTXOP:
+
+    ETHTOOL_RXFLOW_CTXOP_SET		set values for a context (default)
+    ETHTOOL_RXFLOW_CTXOP_NEW		add new RSS context
+    ETHTOOL_RXFLOW_CTXOP_DEL		delete a context
+
+If ETHTOOL_A_RXFLOW_CTXOP is omitted or equal to ETHTOOL_RXFLOW_CTXOP_SET,
+request updates values of an existing RSS context. If ETHTOOL_A_RXFLOW_CONTEXT
+is omitted or zero, main context is updated. ETHTOOL_A_RXFLOW_HASH_FN (bitset)
+specifies hash function(s) to use, ETHTOOL_A_RXFLOW_HASH_KEY hash key (length
+must match) and ETHTOOL_A_RXFLOW_INDIR_TBL requested indirection table in the
+way described above.
+
+ETHTOOL_A_RXFLOW_CTXOP equal to ETHTOOL_RXFLOW_CTXOP_NEW works in the same way
+except ETHTOOL_A_RXFLOW_CONTEXT must not be present and a new RSS context is
+created (if supported by NIC driver). An ETHNL_CMD_SET_RXFLOW message is sent
+as a reply, containing only ETHTOOL_A_RXFLOW_DEV, ETHTOOL_A_RXFLOW_CTXOP
+(equal to ETHTOOL_RXFLOW_CTXOP_NEW) and ETHTOOL_A_RXFLOW_CONTEXT (with new
+context id).
+
+ETHTOOL_A_RXFLOW_CTXOP equal to ETHTOOL_RXFLOW_CTXOP_DEL requests context
+deletion (if supported by NIC driver). Request must have
+ETHTOOL_A_RXFLOW_CONTEXT (which is not zero) and must not contain
+ETHTOOL_A_RXFLOW_HASH_FN, ETHTOOL_A_RXFLOW_HASH_KEY or
+ETHTOOL_A_RXFLOW_INDIR_TBL.
+
+
 Request translation
 -------------------
 
@@ -794,7 +834,7 @@ ETHTOOL_SRXNTUPLE		n/a
 ETHTOOL_GRXNTUPLE		n/a
 ETHTOOL_GSSET_INFO		ETHNL_CMD_GET_STRSET
 ETHTOOL_GRXFHINDIR		ETHNL_CMD_GET_RXFLOW
-ETHTOOL_SRXFHINDIR		n/a
+ETHTOOL_SRXFHINDIR		ETHNL_CMD_SET_RXFLOW
 ETHTOOL_GFEATURES		ETHNL_CMD_GET_SETTINGS
 ETHTOOL_SFEATURES		ETHNL_CMD_SET_SETTINGS
 ETHTOOL_GCHANNELS		ETHNL_CMD_GET_PARAMS
@@ -808,7 +848,7 @@ ETHTOOL_GMODULEEEPROM		n/a
 ETHTOOL_GEEE			ETHNL_CMD_GET_PARAMS
 ETHTOOL_SEEE			ETHNL_CMD_SET_PARAMS
 ETHTOOL_GRSSH			ETHNL_CMD_GET_RXFLOW
-ETHTOOL_SRSSH			n/a
+ETHTOOL_SRSSH			ETHNL_CMD_SET_RXFLOW
 ETHTOOL_GTUNABLE		n/a
 ETHTOOL_STUNABLE		n/a
 ETHTOOL_GPHYSTATS		n/a
diff --git a/include/uapi/linux/ethtool_netlink.h b/include/uapi/linux/ethtool_netlink.h
index 822116b70fca..c6686ebb35b2 100644
--- a/include/uapi/linux/ethtool_netlink.h
+++ b/include/uapi/linux/ethtool_netlink.h
@@ -26,7 +26,7 @@ enum {
 	ETHNL_CMD_ACT_PHYS_ID,
 	ETHNL_CMD_ACT_RESET,
 	ETHNL_CMD_GET_RXFLOW,
-	ETHNL_CMD_SET_RXFLOW,		/* only for reply */
+	ETHNL_CMD_SET_RXFLOW,
 
 	__ETHNL_CMD_CNT,
 	ETHNL_CMD_MAX = (__ETHNL_CMD_CNT - 1)
diff --git a/net/ethtool/netlink.c b/net/ethtool/netlink.c
index 638115536223..a04ec53249cd 100644
--- a/net/ethtool/netlink.c
+++ b/net/ethtool/netlink.c
@@ -747,6 +747,11 @@ static const struct genl_ops ethtool_genl_ops[] = {
 		.dumpit	= ethnl_get_dumpit,
 		.done	= ethnl_get_done,
 	},
+	{
+		.cmd	= ETHNL_CMD_SET_RXFLOW,
+		.flags	= GENL_UNS_ADMIN_PERM,
+		.doit	= ethnl_set_rxflow,
+	},
 };
 
 static const struct genl_multicast_group ethtool_nl_mcgrps[] = {
diff --git a/net/ethtool/netlink.h b/net/ethtool/netlink.h
index 3dad8db40b98..80d22ecbc14e 100644
--- a/net/ethtool/netlink.h
+++ b/net/ethtool/netlink.h
@@ -261,6 +261,7 @@ extern const struct get_request_ops rxflow_request_ops;
 
 int ethnl_set_settings(struct sk_buff *skb, struct genl_info *info);
 int ethnl_set_params(struct sk_buff *skb, struct genl_info *info);
+int ethnl_set_rxflow(struct sk_buff *skb, struct genl_info *info);
 int ethnl_act_nway_rst(struct sk_buff *skb, struct genl_info *info);
 int ethnl_act_phys_id(struct sk_buff *skb, struct genl_info *info);
 int ethnl_act_reset(struct sk_buff *skb, struct genl_info *info);
diff --git a/net/ethtool/rxflow.c b/net/ethtool/rxflow.c
index fe69bf42b7d5..16f3d24d3efe 100644
--- a/net/ethtool/rxflow.c
+++ b/net/ethtool/rxflow.c
@@ -531,3 +531,643 @@ void ethnl_rxflow_notify(struct net_device *dev,
 err_data:
 	rxflow_cleanup(req_info);
 }
+
+/* SET_RXFLOW */
+
+static const struct nla_policy rxflow_set_policy[ETHTOOL_A_RXFLOW_MAX + 1] = {
+	[ETHTOOL_A_RXFLOW_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_DEV]		= { .type = NLA_NESTED },
+	[ETHTOOL_A_RXFLOW_INFOMASK]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_COMPACT]	= { .type = NLA_FLAG },
+	[ETHTOOL_A_RXFLOW_CTXOP]	= { .type = NLA_U32 },
+	[ETHTOOL_A_RXFLOW_CONTEXT]	= { .type = NLA_U32 },
+	[ETHTOOL_A_RXFLOW_NRINGS]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_HASH_FN]	= { .type = NLA_NESTED },
+	[ETHTOOL_A_RXFLOW_HASH_KEY]	= { .type = NLA_BINARY },
+	[ETHTOOL_A_RXFLOW_HASH_OPTS]	= { .type = NLA_NESTED },
+	[ETHTOOL_A_RXFLOW_INDTBL_SIZE]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXFLOW_INDIR_TBL]	= { .type = NLA_NESTED },
+};
+
+/* check request validity, return 0 if OK, negative error if not */
+static int rxflow_set_sanity_checks(struct nlattr *tb[], struct genl_info *info,
+				    u32 ctxop, u32 context)
+{
+	struct nlattr *err_attr;
+
+	switch(ctxop) {
+	case ETHTOOL_RXFLOW_CTXOP_SET :
+		break;
+	case ETHTOOL_RXFLOW_CTXOP_NEW :
+		if (context) {
+			NL_SET_ERR_MSG_ATTR(info->extack,
+					    tb[ETHTOOL_A_RXFLOW_CONTEXT],
+					    "cannot set context id for new context");
+			return -EINVAL;
+		}
+		if (tb[ETHTOOL_A_RXFLOW_HASH_OPTS]) {
+			NL_SET_ERR_MSG_ATTR(info->extack,
+					    tb[ETHTOOL_A_RXFLOW_HASH_OPTS],
+					    "hash options not allowed with new context");
+			return -EINVAL;
+		}
+		break;
+	case ETHTOOL_RXFLOW_CTXOP_DEL :
+		if (!context) {
+			GENL_SET_ERR_MSG(info, "cannot delete main context");
+			return -EINVAL;
+		}
+		err_attr = tb[ETHTOOL_A_RXFLOW_HASH_FN] ?:
+			   (tb[ETHTOOL_A_RXFLOW_HASH_KEY] ?:
+			    (tb[ETHTOOL_A_RXFLOW_HASH_OPTS] ?:
+			     tb[ETHTOOL_A_RXFLOW_INDIR_TBL]));
+		if (err_attr) {
+			NL_SET_ERR_MSG_ATTR(info->extack, err_attr,
+					    "data passed when deleting context");
+			return -EINVAL;
+		}
+		break;
+	default:
+		NL_SET_ERR_MSG_ATTR(info->extack, tb[ETHTOOL_A_RXFLOW_CTXOP],
+				    "unknown context operation");
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static const u32 all_bits = ~(u32)0;
+
+static const struct nla_policy rxhashopt_policy[ETHTOOL_A_RXHASHOPT_MAX + 1] = {
+	[ETHTOOL_A_RXHASHOPT_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_RXHASHOPT_FLOWTYPE]	= { .type = NLA_U32 },
+	[ETHTOOL_A_RXHASHOPT_FIELDS]	= { .type = NLA_BITFIELD32,
+					    .validation_data = &all_bits },
+	[ETHTOOL_A_RXHASHOPT_DISCARD]	= { .type = NLA_FLAG },
+};
+
+static int rxflow_set_hash_opts(struct net_device *dev, unsigned int context,
+				const struct nlattr *opts_attr,
+				struct genl_info *info)
+{
+	const struct ethtool_ops *ops = dev->ethtool_ops;
+	struct nlattr *tb[ETHTOOL_A_RXHASHOPT_MAX + 1];
+	const struct nlattr *opt_attr;
+	int ret, rem;
+
+	if (!ops->get_rxnfc || !ops->set_rxnfc)
+		return -EOPNOTSUPP;
+
+	nla_for_each_nested(opt_attr, opts_attr, rem) {
+		struct ethtool_rxnfc rxnfc = {
+			.cmd		= ETHTOOL_SRXFH,
+			.rss_context	= context,
+		};
+		struct ethtool_rxflow_notification_info ninfo = {
+			.context	= context,
+		};
+
+		if (nla_type(opt_attr) != ETHTOOL_A_RXHASHOPTS_OPT) {
+				NL_SET_ERR_MSG_ATTR(info->extack, opt_attr,
+						    "unexpected attribute in ETHTOOL_A_RXFLOW_HASH_OPTS");
+			return -EINVAL;
+		}
+		ret = nla_parse_nested(tb, ETHTOOL_A_RXHASHOPT_MAX, opt_attr,
+				       rxhashopt_policy, info->extack);
+		if (ret < 0)
+			return ret;
+		if (tb[ETHTOOL_A_RXHASHOPT_DISCARD] &&
+		    tb[ETHTOOL_A_RXHASHOPT_FIELDS])
+			return -EINVAL;
+		if (!tb[ETHTOOL_A_RXHASHOPT_FLOWTYPE] ||
+		    (!tb[ETHTOOL_A_RXHASHOPT_DISCARD] &&
+		     !tb[ETHTOOL_A_RXHASHOPT_FIELDS]))
+			return -EINVAL;
+
+		ninfo.flow_type = nla_get_u32(tb[ETHTOOL_A_RXHASHOPT_FLOWTYPE]);
+		rxnfc.flow_type = ninfo.flow_type | (context ? FLOW_RSS : 0);
+		if (tb[ETHTOOL_A_RXHASHOPT_DISCARD]) {
+			rxnfc.data = RXH_DISCARD;
+		} else {
+			struct ethtool_rxnfc grxnfc = rxnfc;
+			struct nla_bitdield32;
+			u32 fields;
+
+			grxnfc.cmd = ETHTOOL_GRXFH;
+			ret = ops->get_rxnfc(dev, &grxnfc, NULL);
+			if (ret < 0)
+				return ret;
+			fields = (grxnfc.data & RXH_DISCARD) ? 0 : grxnfc.data;
+			if (!ethnl_update_bitfield32(&fields,
+						     tb[ETHTOOL_A_RXHASHOPT_FIELDS]))
+				continue;
+			rxnfc.data = fields;
+		}
+
+		ret = ops->set_rxnfc(dev, &rxnfc);
+		if (ret < 0)
+			return ret;
+		ethnl_rxflow_notify(dev, info->extack, ETHNL_CMD_SET_RXFLOW,
+				    ETHTOOL_IM_RXFLOW_HASHOPTS, &ninfo);
+	}
+
+	return 0;
+}
+
+static int rxflow_set_prepare_hashfn(struct net_device *dev,
+				  struct genl_info *info,
+				  const struct nlattr *attr, u8 *phashfn,
+				  u32 *info_mask)
+{
+	u32 hash_fn = 0;
+	bool mod;
+	int ret;
+
+	if (!attr) {
+		*phashfn = ETH_RSS_HASH_NO_CHANGE;
+		return 0;
+	}
+	mod = ethnl_update_bitset32(&hash_fn, NULL, ETH_RSS_HASH_FUNCS_COUNT,
+				    attr, &ret, rss_hash_func_strings, true,
+				    info);
+	if (ret < 0)
+		return ret;
+	if (hash_fn > U8_MAX) {
+		NL_SET_ERR_MSG_ATTR(info->extack, attr,
+				    "only first 8 hash functions supported");
+		ret = -EINVAL;
+	} else {
+		*phashfn = mod ? (u8)hash_fn : ETH_RSS_HASH_NO_CHANGE;
+		*info_mask |= (mod ? ETHTOOL_IM_RXFLOW_HASHFN : 0);
+	}
+	return ret;
+}
+
+static int rxflow_set_prepare_hkey(struct net_device *dev, struct genl_info *info,
+				const struct nlattr *attr, u8 **phkey,
+				u32 *info_mask)
+{
+	const struct ethtool_ops *ops = dev->ethtool_ops;
+	u32 hkey_size = 0;
+
+	*phkey = NULL;
+	if (!attr)
+		return 0;
+	if (ops->get_rxfh_key_size)
+		hkey_size = ops->get_rxfh_key_size(dev);
+	if (!hkey_size)
+		return -EOPNOTSUPP;
+	if (nla_len(attr) != hkey_size) {
+		NL_SET_ERR_MSG_ATTR(info->extack, attr,
+				    "hash key size does not match");
+		return -EINVAL;
+	}
+
+	*phkey = nla_data(attr);
+	*info_mask |= ETHTOOL_IM_RXFLOW_HKEY;
+	return 0;
+}
+
+static const struct nla_policy indtbl_block_policy[ETHTOOL_A_ITBLK_MAX + 1] = {
+	[ETHTOOL_A_ITBLK_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_ITBLK_START]	= { .type = NLA_U32 },
+	[ETHTOOL_A_ITBLK_LEN]	= { .type = NLA_U32 },
+	[ETHTOOL_A_ITBLK_DATA]	= { .type = NLA_BINARY },
+};
+
+static int rxflow_indtbl_apply_block(u32 *table, unsigned int size,
+				     const struct nlattr *block,
+				     unsigned int nrings,
+				     unsigned int entry_size,
+				     struct genl_info *info)
+{
+	struct nlattr *tb[ETHTOOL_A_ITBLK_MAX + 1];
+	const u32 *src32;
+	const u16 *src16;
+	const u8 *src8;
+	unsigned int start, blen, i;
+	int ret;
+
+	ret = nla_parse_nested(tb, ETHTOOL_A_ITBLK_MAX, block,
+			       indtbl_block_policy, info->extack);
+	if (ret < 0)
+		return ret;
+	if (tb[ETHTOOL_A_ITBLK_DATA])
+		return -EINVAL;
+
+	start = tb[ETHTOOL_A_ITBLK_START] ?
+		nla_get_u32(tb[ETHTOOL_A_ITBLK_START]) : 0;
+	if (start >= size)
+		return -EINVAL;
+	if (tb[ETHTOOL_A_ITBLK_LEN]) {
+		blen = nla_get_u32(tb[ETHTOOL_A_ITBLK_LEN]);
+		if (start + blen > size)
+			return -EINVAL;
+	} else {
+		blen = size - start;
+	}
+	if (nla_len(tb[ETHTOOL_A_ITBLK_DATA]) < blen * entry_size)
+		return -EINVAL;
+
+	switch(entry_size) {
+	case 4:
+		src32 = nla_data(tb[ETHTOOL_A_ITBLK_DATA]);
+		for (i = 0; i < blen; i++)
+			if (src32[i] >= nrings)
+				goto data_err;
+		memcpy(table + start, src32, blen * entry_size);
+		break;
+	case 2:
+		src16 = nla_data(tb[ETHTOOL_A_ITBLK_DATA]);
+		for (i = 0; i < blen; i++) {
+			if (src16[i] >= nrings)
+				goto data_err;
+			table[start + i] = src16[i];
+		}
+		break;
+	case 1:
+		src8 = nla_data(tb[ETHTOOL_A_ITBLK_DATA]);
+		for (i = 0; i < blen; i++) {
+			if (src8[i] >= nrings)
+				goto data_err;
+			table[start + i] = src8[i];
+		}
+		break;
+	}
+
+	return 0;
+data_err:
+	NL_SET_ERR_MSG_ATTR(info->extack, tb[ETHTOOL_A_ITBLK_DATA],
+			    "indtbl entry exceeds max ring number");
+	return -EINVAL;
+}
+
+static const struct nla_policy indtbl_pattern_policy[ETHTOOL_A_ITPAT_MAX + 1] = {
+	[ETHTOOL_A_ITPAT_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_ITPAT_START]		= { .type = NLA_U32 },
+	[ETHTOOL_A_ITPAT_LEN]		= { .type = NLA_U32 },
+	[ETHTOOL_A_ITPAT_MIN_RING]	= { .type = NLA_U32 },
+	[ETHTOOL_A_ITPAT_MAX_RING]	= { .type = NLA_U32 },
+	[ETHTOOL_A_ITPAT_OFFSET]	= { .type = NLA_U32 },
+};
+
+static int rxflow_indtbl_apply_pattern(u32 *table, unsigned int size,
+				const struct nlattr *pattern,
+				unsigned int n_rings, struct genl_info *info)
+{
+	struct nlattr *tb[ETHTOOL_A_ITPAT_MAX + 1];
+	unsigned int max_ring = n_rings - 1;
+	unsigned int blen, mod, n, i;
+	unsigned int min_ring = 0;
+	unsigned int offset = 0;
+	unsigned int start = 0;
+	int ret;
+
+	ret = nla_parse_nested(tb, ETHTOOL_A_ITPAT_MAX, pattern,
+			       indtbl_pattern_policy, info->extack);
+	if (ret < 0)
+		return ret;
+
+	if (tb[ETHTOOL_A_ITPAT_START])
+		start = nla_get_u32(tb[ETHTOOL_A_ITPAT_START]);
+	if (start >= size)
+		return -EINVAL;
+	if (tb[ETHTOOL_A_ITPAT_LEN]) {
+		blen = nla_get_u32(tb[ETHTOOL_A_ITPAT_LEN]);
+		if (start + blen > size)
+			return -EINVAL;
+	} else {
+		blen = size - start;
+	}
+	if (tb[ETHTOOL_A_ITPAT_MIN_RING])
+		min_ring = nla_get_u32(tb[ETHTOOL_A_ITPAT_MIN_RING]);
+	if (tb[ETHTOOL_A_ITPAT_MAX_RING])
+		max_ring = nla_get_u32(tb[ETHTOOL_A_ITPAT_MAX_RING]);
+	if (tb[ETHTOOL_A_ITPAT_OFFSET])
+		offset = nla_get_u32(tb[ETHTOOL_A_ITPAT_OFFSET]);
+	if (min_ring >= n_rings || max_ring < min_ring || max_ring >= n_rings)
+		return -EINVAL;
+	mod = max_ring - min_ring + 1;
+
+	for (i = 0; i < blen && i < mod; i++)
+		table[start + i] = min_ring + (start + i + offset) % mod;
+	n = blen / mod;
+	for (i = 0; i < n - 1; i++)
+		memcpy(table + start + i * mod, table + start,
+		       mod * sizeof(table[0]));
+	if (blen % mod)
+		memcpy(table + start + n * mod, table + start, blen % mod);
+
+	return 0;
+}
+
+static const struct nla_policy indtbl_weights_policy[ETHTOOL_A_ITWGHT_MAX + 1] = {
+	[ETHTOOL_A_ITWGHT_UNSPEC]	= { .type = NLA_REJECT },
+	[ETHTOOL_A_ITWGHT_VALUES]	= { .type = NLA_BINARY },
+	[ETHTOOL_A_ITWGHT_WEIGHTS]	= { .type = NLA_BINARY },
+};
+
+static int rxflow_indtbl_apply_weights(u32 *table, unsigned int size,
+				const struct nlattr *attr, unsigned int n_rings,
+				struct genl_info *info)
+{
+	struct nlattr *tb[ETHTOOL_A_ITWGHT_MAX + 1];
+	const u32 *weights = NULL;
+	const u32 *values = NULL;
+	unsigned int sum = 0;
+	unsigned int count;
+	int ring, ret, i;
+	s64 balance;
+
+	ret = nla_parse_nested(tb, ETHTOOL_A_ITWGHT_MAX, attr,
+			       indtbl_weights_policy, info->extack);
+	if (ret < 0)
+		return ret;
+	if (!tb[ETHTOOL_A_ITWGHT_WEIGHTS] ||
+	    (nla_len(tb[ETHTOOL_A_ITWGHT_WEIGHTS]) % sizeof(weights[0])))
+		return -EINVAL;
+	weights = nla_data(tb[ETHTOOL_A_ITWGHT_WEIGHTS]);
+	count = nla_len(tb[ETHTOOL_A_ITWGHT_WEIGHTS]) / sizeof(weights[0]);
+	if (!count)
+		return -EINVAL;
+	if (tb[ETHTOOL_A_ITWGHT_VALUES]) {
+		values = nla_data(tb[ETHTOOL_A_ITWGHT_VALUES]);
+		if (nla_len(tb[ETHTOOL_A_ITWGHT_VALUES]) !=
+		    nla_len(tb[ETHTOOL_A_ITWGHT_WEIGHTS]))
+			return -EINVAL;
+	}
+
+	sum = 0;
+	for (i = 0; i < count; i++) {
+		if (weights[i] > size - sum)
+			return -EINVAL;
+		sum += weights[i];
+	}
+	if (!sum)
+		return -EINVAL;
+
+	/* This is the same algorithm as in fill_indir_table() in ethtool.
+	 * Our balance is  i * sum - (*indir_size) * partial + sum - 1
+	 * there. Adding sum -1 compensates for absence of the rounding error
+	 * in ethtool code.
+	 */
+	balance = sum - 1;
+	ring = -1;
+	for (i = 0; i < size; i++) {
+		while (balance >= 0)
+			balance -= size * weights[++ring];
+		table[i] = values ? values[ring] : ring;
+		balance += sum;
+	}
+
+	return 0;
+}
+
+static int rxflow_set_prepare_indtbl(struct net_device *dev,
+				  struct genl_info *info,
+				  const struct nlattr *attr, u32 **pindtbl,
+				  u32 *info_mask, bool *reset)
+{
+	struct ethtool_rxnfc rx_rings = { .cmd = ETHTOOL_GRXRINGS };
+	const struct ethtool_ops *ops = dev->ethtool_ops;
+	const struct nlattr *patch;
+	bool mod = false;
+	int ret, rem;
+	u32 size = 0;
+	u32 *table;
+	u32 nrings;
+
+	*reset = false;
+	*pindtbl = NULL;
+	if (!attr)
+		return 0;
+	if (!ops->get_rxnfc)
+		return -EOPNOTSUPP;
+	ret = ops->get_rxnfc(dev, &rx_rings, NULL);
+	if (ret < 0)
+		return ret;
+	nrings = rx_rings.data;
+	if (ops->get_rxfh_indir_size)
+		size = ops->get_rxfh_indir_size(dev);
+	if (!size)
+		return -EOPNOTSUPP;
+	table = kcalloc(size, sizeof(table[0]), GFP_KERNEL);
+	if (!table)
+		return -ENOMEM;
+	*pindtbl = 0;
+
+	nla_for_each_nested(patch, attr, rem) {
+		int ptype = nla_type(patch);
+
+		switch(ptype) {
+		case ETHTOOL_A_INDTBL_BLOCK32:
+			ret = rxflow_indtbl_apply_block(table, size, patch,
+							nrings, 4, info);
+			break;
+		case ETHTOOL_A_INDTBL_BLOCK16:
+			ret = rxflow_indtbl_apply_block(table, size, patch,
+							nrings, 2, info);
+			break;
+		case ETHTOOL_A_INDTBL_BLOCK8:
+			ret = rxflow_indtbl_apply_block(table, size, patch,
+							nrings, 1, info);
+			break;
+		case ETHTOOL_A_INDTBL_PATTERN:
+			ret = rxflow_indtbl_apply_pattern(table, size, patch,
+							  nrings, info);
+			break;
+		case ETHTOOL_A_INDTBL_WEIGHTS:
+			ret = rxflow_indtbl_apply_weights(table, size, patch,
+							  nrings, info);
+			break;
+		default:
+			NL_SET_ERR_MSG_ATTR(info->extack, attr,
+					    "unknown indir table patch type");
+			return -EOPNOTSUPP;
+		}
+		if (ret < 0) {
+			kfree(table);
+			return ret;
+		}
+		mod = true;
+	}
+	if (!mod) {
+		unsigned int i;
+
+		for (i = 0; i < size; i++)
+			table[i] = i % nrings;
+		*reset = true;
+	}
+	*pindtbl = table;
+	*info_mask |= ETHTOOL_IM_RXFLOW_INDTBL;
+
+	return 0;
+}
+
+static int rxflow_set_delete_context(struct net_device *dev, u32 context,
+				     struct genl_info *info)
+{
+	const struct ethtool_ops *ops = dev->ethtool_ops;
+	int ret;
+
+	ret = ops->set_rxfh_context(dev, NULL, NULL, ETH_RSS_HASH_NO_CHANGE,
+				    &context, true);
+	if (ret == 0) {
+		struct ethtool_rxflow_notification_info ninfo = {
+			.ctx_op		= ETHTOOL_RXFLOW_CTXOP_DEL,
+			.context	= context,
+		};
+
+		ethnl_rxflow_notify(dev, info->extack, ETHNL_CMD_SET_RXFLOW, 0,
+				    &ninfo);
+	}
+	return ret;
+}
+
+static int rxflow_set_send_reply(struct net_device *dev,
+				 struct genl_info *info, u32 context)
+{
+	struct sk_buff *skb;
+	void *reply_payload;
+	int reply_len;
+	int ret;
+
+	reply_len = ethnl_dev_size();
+	reply_len += 2 * nla_total_size(sizeof(u32));
+	skb = ethnl_reply_init(reply_len, dev, ETHNL_CMD_SET_RXFLOW,
+			       ETHTOOL_A_RXFLOW_DEV, info, &reply_payload);
+	if (!skb)
+		return -ENOMEM;
+	ret = ethnl_fill_dev(skb, dev, ETHTOOL_A_RXFLOW_DEV);
+	if (ret < 0)
+		goto err_skb;
+	ret = -EMSGSIZE;
+	if (nla_put_u32(skb, ETHTOOL_A_RXFLOW_CTXOP, ETHTOOL_RXFLOW_CTXOP_NEW) ||
+	    nla_put_u32(skb, ETHTOOL_A_RXFLOW_CONTEXT, context))
+		goto err_skb;
+
+	genlmsg_end(skb, reply_payload);
+	return genlmsg_reply(skb, info);
+
+err_skb:
+	WARN_ONCE(ret == -EMSGSIZE,
+		  "calculated message payload length (%d) not sufficient\n",
+		  reply_len);
+	if (skb)
+		nlmsg_free(skb);
+	return ret;
+}
+
+int ethnl_set_rxflow(struct sk_buff *skb, struct genl_info *info)
+{
+	struct nlattr *tb[ETHTOOL_A_RXFLOW_MAX + 1];
+	unsigned int ctxop = ETHTOOL_RXFLOW_CTXOP_SET;
+	const struct ethtool_ops *ops;
+	struct net_device *dev;
+	u32 *indtbl = NULL;
+	bool reset_indtbl;
+	u32 info_mask = 0;
+	u32 context = 0;
+	bool do_rxfh;
+	u8 hash_fn;
+	u8 *hkey;
+	int ret;
+
+	ret = nlmsg_parse(info->nlhdr, GENL_HDRLEN, tb, ETHTOOL_A_RXFLOW_MAX,
+			  rxflow_set_policy, info->extack);
+	if (ret < 0)
+		return ret;
+	if (tb[ETHTOOL_A_RXFLOW_CONTEXT])
+		context = nla_get_u32(tb[ETHTOOL_A_RXFLOW_CONTEXT]);
+	if (tb[ETHTOOL_A_RXFLOW_CTXOP])
+		ctxop = nla_get_u32(tb[ETHTOOL_A_RXFLOW_CTXOP]);
+	ret = rxflow_set_sanity_checks(tb, info, ctxop, context);
+	if (ret < 0)
+		return ret;
+	do_rxfh = tb[ETHTOOL_A_RXFLOW_HASH_FN] ||
+		  tb[ETHTOOL_A_RXFLOW_HASH_KEY] ||
+		  tb[ETHTOOL_A_RXFLOW_INDIR_TBL];
+
+	dev = ethnl_dev_get(info, tb[ETHTOOL_A_RXFLOW_DEV]);
+	if (IS_ERR(dev))
+		return PTR_ERR(dev);
+	ops = dev->ethtool_ops;
+
+	rtnl_lock();
+	ret = ethnl_before_ops(dev);
+	if (ret < 0)
+		goto out_rtnl;
+
+	if (tb[ETHTOOL_A_RXFLOW_HASH_OPTS]) {
+		ret = rxflow_set_hash_opts(dev, context,
+					   tb[ETHTOOL_A_RXFLOW_HASH_OPTS],
+					   info);
+		if (ret < 0)
+			goto out_ops;
+	}
+	if (!do_rxfh)
+		goto out_ops;
+
+	ret = -EOPNOTSUPP;
+	if (context && (!ops->get_rxfh_context || !ops->set_rxfh_context))
+		goto out_ops;
+	if (!context && (!ops->get_rxfh || !ops->set_rxfh))
+		goto out_ops;
+
+	if (ctxop == ETHTOOL_RXFLOW_CTXOP_DEL) {
+		ret = rxflow_set_delete_context(dev, context, info);
+		goto out_ops;
+	}
+	if (ctxop == ETHTOOL_RXFLOW_CTXOP_NEW)
+		context = ETH_RXFH_CONTEXT_ALLOC;
+	ret = rxflow_set_prepare_hashfn(dev, info, tb[ETHTOOL_A_RXFLOW_HASH_FN],
+					&hash_fn, &info_mask);
+	if (ret < 0)
+		goto out_ops;
+	ret = rxflow_set_prepare_hkey(dev, info, tb[ETHTOOL_A_RXFLOW_HASH_KEY],
+				   &hkey, &info_mask);
+	if (ret < 0)
+		goto out_free;
+	ret = rxflow_set_prepare_indtbl(dev, info,
+					tb[ETHTOOL_A_RXFLOW_INDIR_TBL],
+					&indtbl, &info_mask, &reset_indtbl);
+	if (ret < 0)
+		goto out_free;
+	if (context)
+		ret = ops->set_rxfh_context(dev, indtbl, hkey, hash_fn,
+					    &context, false);
+	else
+		ret = ops->set_rxfh(dev, indtbl, hkey, hash_fn);
+	if (ret == 0 && !context && tb[ETHTOOL_A_RXFLOW_INDIR_TBL]) {
+		/* indicate whether rxfh was set to default */
+		if (reset_indtbl)
+			dev->priv_flags |= IFF_RXFH_CONFIGURED;
+		else
+			dev->priv_flags &= ~IFF_RXFH_CONFIGURED;
+	}
+	if (ctxop == ETHTOOL_RXFLOW_CTXOP_NEW && ret == 0) {
+		ret = rxflow_set_send_reply(dev, info, context);
+		if (ret < 0) {
+			GENL_SET_ERR_MSG(info, "failed to send reply message");
+			ret = 0;
+		}
+	}
+
+out_free:
+	kfree(indtbl);
+out_ops:
+	if (ret == 0 && (info_mask || ctxop != ETHTOOL_RXFLOW_CTXOP_SET)) {
+		const struct ethtool_rxflow_notification_info ninfo = {
+			.ctx_op		= ctxop,
+			.context	= context,
+		};
+
+		ethnl_rxflow_notify(dev, info->extack, ETHNL_CMD_SET_RXFLOW,
+				    info_mask, &ninfo);
+	}
+	ethnl_after_ops(dev);
+out_rtnl:
+	rtnl_unlock();
+	dev_put(dev);
+	return ret;
+}
-- 
2.21.0

